#!/usr/bin/env python3

"""

HBase Student Hands-On Lab Script

Module 12: Scalable Computing - HBase NoSQL Database

This script provides hands-on exercises for students to learn HBase concepts

using Python and HappyBase, bridging the gap between the Java lab and

practical data science workflows.

Usage:

    python student_hbase_lab.py

Prerequisites:

    pip install happybase pandas numpy matplotlib seaborn thrift

Terminal commands to run before starting:

    # 1. Check Python version

    python --version

    # 2. Install required packages

    pip install happybase pandas numpy matplotlib seaborn thrift

    # 3. Download Titanic dataset

    curl -o titanic.csv https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time
import sys
from typing import List, Tuple, Dict, Any

# Set up plotting style
plt.style.use('default')
sns.set_palette("husl")

def print_header(title: str):
    """Print a formatted header"""
    print(f"\n{'='*60}")
    print(f"ðŸš€ {title}")
    print(f"{'='*60}")

def check_environment():
    """Check if all required packages are available"""
    print_header("Environment Check")

    # Check Python version
    print(f"Python version: {sys.version}")

    # Test basic imports
    try:
        import pandas as pd
        import numpy as np
        import matplotlib.pyplot as plt
        import seaborn as sns
        print("SUCCESS: Core data science libraries imported successfully")
    except ImportError as e:
        print(f"ERROR: Import error: {e}")
        print("Run: pip install pandas numpy matplotlib seaborn")
        return False

    # Test HappyBase (HBase client)
    try:
        import happybase
        print("SUCCESS: HappyBase imported successfully")
    except ImportError as e:
        print(f"ERROR: HappyBase import error: {e}")
        print("Run: pip install happybase")
        print("Note: HappyBase requires HBase Thrift server to be running")
        return False

    print("\nOBJECTIVE: Ready to start the HBase lab!")
    return True

def load_titanic_data() -> pd.DataFrame:
    """Load Titanic dataset with fallback to generated data"""
    try:
        df = pd.read_csv('titanic.csv')
        print(f"SUCCESS: Titanic dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns")
        print(".2f")
        return df
    except FileNotFoundError:
        print("ERROR: titanic.csv not found. Download it first:")
        print("curl -o titanic.csv https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv")
        print("ðŸ“ Using generated sample data for demo")

        # Create sample data for demo
        np.random.seed(42)
        df = pd.DataFrame({
            'PassengerId': range(1, 892),
            'Survived': np.random.choice([0, 1], 891),
            'Pclass': np.random.choice([1, 2, 3], 891),
            'Name': [f'Passenger_{i}' for i in range(891)],
            'Sex': np.random.choice(['male', 'female'], 891),
            'Age': np.random.normal(30, 15, 891).clip(0, 80),
            'Fare': np.random.exponential(30, 891)
        })
        return df

## ðŸ—„ï¸ Lab 1: Understanding HBase Data Model

### Exercise 1.1: Design HBase Table Schema

**Objective:** Design an HBase table schema for the Titanic dataset

**Instructions:**
1. Analyze the Titanic dataset columns
2. Group related columns into logical column families
3. Choose appropriate row key design
4. Consider data access patterns

**Questions to Consider:**
- Which columns are frequently accessed together?
- What would be a good row key for this data?
- How would you handle sparse columns?
def exercise_1_1_schema_design(df: pd.DataFrame):
    """Exercise: Design HBase table schema"""
    print_header("Lab 1: HBase Schema Design")

    print("ANALYSIS: Titanic Dataset Columns:")
    for i, col in enumerate(df.columns, 1):
        null_pct = df[col].isnull().sum() / len(df) * 100
        print("2d")

    print("
OBJECTIVE: Your Task:"    print("Design an HBase table schema by grouping columns into families:")
    print("1. Analyze which columns are related")
    print("2. Consider access patterns (reads/writes)")
    print("3. Think about data sparsity")

    print("
ðŸ’¡ Suggested Column Families:"    print("â€¢ personal: Name, Sex, Age")
    print("â€¢ travel: Pclass, Fare, Embarked")
    print("â€¢ outcome: Survived, Ticket")

    # Student should modify this schema
    proposed_schema = {
        'personal': ['Name', 'Sex', 'Age'],
        'travel': ['Pclass', 'Fare', 'Embarked'],
        'outcome': ['Survived', 'Ticket']
    }

    print("
ðŸ“‹ Proposed Schema:"    for family, columns in proposed_schema.items():
        print(f"  {family}: {', '.join(columns)}")

    return proposed_schema

## ðŸ”§ Lab 2: HBase CRUD Operations

### Exercise 2.1: Basic Table Operations

**Objective:** Learn basic HBase operations (Create, Read, Update, Delete)

**Instructions:**
1. Create an HBase table
2. Insert data using different methods
3. Read data with various options
4. Update existing data
5. Delete data
def exercise_2_1_basic_operations(df: pd.DataFrame, schema: Dict):
    """Exercise: Basic HBase CRUD operations"""
    print_header("Lab 2: Basic HBase Operations")

    try:
        import happybase

        # Connect to HBase
        connection = happybase.Connection('localhost', port=9090)
        table_name = 'student_titanic_lab'

        # Create table from schema
        families = {family: dict(max_versions=1) for family in schema.keys()}
        try:
            connection.create_table(table_name, families)
            print(f"SUCCESS: Created table '{table_name}'")
        except:
            print(f"âš ï¸ Table '{table_name}' already exists")

        table = connection.table(table_name)

        # Exercise 2.1a: Insert single row
        print("
ðŸ“ Exercise 2.1a: Insert Single Row"        passenger = df.iloc[0]
        row_key = str(passenger['PassengerId']).encode('utf-8')

        # Prepare data for insertion
        data = {}
        for family, columns in schema.items():
            for col in columns:
                if col in passenger.index and not pd.isna(passenger[col]):
                    key = f"{family}:{col.lower()}".encode('utf-8')
                    value = str(passenger[col]).encode('utf-8')
                    data[key] = value

        table.put(row_key, data)
        print(f"SUCCESS: Inserted passenger {passenger['PassengerId']}")

        # Exercise 2.1b: Read single row
        print("
ðŸ“– Exercise 2.1b: Read Single Row"        retrieved = table.row(row_key)
        print("Retrieved data:")
        for key, value in retrieved.items():
            print(f"  {key.decode('utf-8')}: {value.decode('utf-8')}")

        # Exercise 2.1c: Insert multiple rows
        print("
ðŸ“ Exercise 2.1c: Insert Multiple Rows"        batch_size = 10
        with table.batch(batch_size=batch_size) as b:
            for i in range(1, batch_size):
                passenger = df.iloc[i]
                row_key = str(passenger['PassengerId']).encode('utf-8')
                data = {}
                for family, columns in schema.items():
                    for col in columns:
                        if col in passenger.index and not pd.isna(passenger[col]):
                            key = f"{family}:{col.lower()}".encode('utf-8')
                            value = str(passenger[col]).encode('utf-8')
                            data[key] = value
                b.put(row_key, data)
        print(f"SUCCESS: Batch inserted {batch_size-1} more passengers")

        # Exercise 2.1d: Scan rows
        print("
ðŸ” Exercise 2.1d: Scan Rows"        count = 0
        for key, data in table.scan(limit=5):
            count += 1
            print(f"Row {count}: Key={key.decode('utf-8')}")
            for col_key, col_value in data.items():
                print(f"  {col_key.decode('utf-8')}: {col_value.decode('utf-8')}")
            print()

        connection.close()

    except Exception as e:
        print(f"ERROR: HBase operations failed: {e}")
        print("ðŸ’¡ Continuing with conceptual exercises...")

## ANALYSIS: Lab 3: HBase Query Patterns

### Exercise 3.1: Column Family Queries

**Objective:** Learn to query specific column families and columns

**Instructions:**
1. Query entire column families
2. Query specific columns within families
3. Compare performance of different query patterns
def exercise_3_1_column_queries(df: pd.DataFrame, schema: Dict):
    """Exercise: Column family and column-specific queries"""
    print_header("Lab 3: HBase Query Patterns")

    try:
        import happybase
        connection = happybase.Connection('localhost', port=9090)
        table = connection.table('student_titanic_lab')

        # Exercise 3.1a: Query specific column family
        print("
OBJECTIVE: Exercise 3.1a: Query Column Family"        row_key = b'1'
        personal_data = table.row(row_key, columns=[b'personal'])
        print("Personal data only:")
        for key, value in personal_data.items():
            print(f"  {key.decode('utf-8')}: {value.decode('utf-8')}")

        # Exercise 3.1b: Query specific columns
        print("
OBJECTIVE: Exercise 3.1b: Query Specific Columns"        specific_cols = [b'personal:name', b'outcome:survived', b'travel:pclass']
        specific_data = table.row(row_key, columns=specific_cols)
        print("Specific columns only:")
        for key, value in specific_data.items():
            print(f"  {key.decode('utf-8')}: {value.decode('utf-8')}")

        # Exercise 3.1c: Scan with column filters
        print("
OBJECTIVE: Exercise 3.1c: Scan with Column Filters"        count = 0
        for key, data in table.scan(columns=[b'personal:name', b'outcome:survived'], limit=3):
            count += 1
            print(f"Passenger {key.decode('utf-8')}: {data[b'personal:name'].decode('utf-8')} - Survived: {data[b'outcome:survived'].decode('utf-8')}")

        connection.close()

    except Exception as e:
        print(f"ERROR: Query exercises failed: {e}")
        print("ðŸ’¡ Continuing with conceptual exercises...")

## ðŸ“ˆ Lab 4: Performance Analysis

### Exercise 4.1: HBase vs Pandas Performance

**Objective:** Compare HBase and pandas performance for different operations

**Instructions:**
1. Time various operations in both systems
2. Analyze when HBase performs better/worse than pandas
3. Understand the performance trade-offs
def exercise_4_1_performance_comparison(df: pd.DataFrame):
    """Exercise: Compare HBase vs pandas performance"""
    print_header("Lab 4: Performance Analysis")

    # Pandas operations
    print("ðŸ¼ Pandas Performance Tests:")

    # Test 1: Simple filtering
    start_time = time.time()
    survived = df[df['Survived'] == 1]
    pandas_filter_time = time.time() - start_time
    print(".4f")

    # Test 2: Group by operation
    start_time = time.time()
    survival_by_class = df.groupby('Pclass')['Survived'].mean()
    pandas_groupby_time = time.time() - start_time
    print(".4f")

    # Test 3: Complex query
    start_time = time.time()
    complex_query = df[(df['Pclass'] == 1) & (df['Sex'] == 'female') & (df['Age'] > 20)]
    pandas_complex_time = time.time() - start_time
    print(".4f")

    print("
ðŸ’­ When would HBase be faster than pandas?"    print("â€¢ Large datasets that don't fit in memory")
    print("â€¢ Write-heavy workloads")
    print("â€¢ Concurrent read/write operations")
    print("â€¢ Distributed processing needs")

    print("
ðŸ’­ When would pandas be faster than HBase?"    print("â€¢ Small datasets (< 100MB)")
    print("â€¢ Complex analytical queries")
    print("â€¢ Single-user, read-only analysis")
    print("â€¢ When you need all data in memory")

## ðŸ” Lab 5: Data Modeling Best Practices

### Exercise 5.1: Row Key Design

**Objective:** Learn best practices for HBase row key design

**Instructions:**
1. Analyze different row key design options
2. Consider access patterns and distribution
3. Think about hot spot avoidance
def exercise_5_1_row_key_design(df: pd.DataFrame):
    """Exercise: Row key design best practices"""
    print_header("Lab 5: Row Key Design")

    print("ðŸ”‘ Row Key Design Options for Titanic Data:")
    print("""
Option 1: PassengerId (Sequential)
  Pros: Simple, matches source data
  Cons: Hot spots, poor distribution

Option 2: Reversed PassengerId
  Pros: Better distribution
  Cons: Less intuitive

Option 3: Class + Random Suffix
  Pros: Good distribution, enables range scans by class
  Cons: More complex

Option 4: Hash-based
  Pros: Perfect distribution
  Cons: No range scan capability
    """)

    # Demonstrate different row key strategies
    sample_passengers = df.head(5)

    print("ðŸ“‹ Sample Row Key Designs:")
    for _, passenger in sample_passengers.iterrows():
        pid = passenger['PassengerId']
        pclass = passenger['Pclass']

        print(f"Passenger {pid} (Class {pclass}):")
        print(f"  Sequential: {pid}")
        print(f"  Reversed: {str(pid)[::-1]}")
        print(f"  Class-based: {pclass:02d}_{pid:04d}")
        print(f"  Hashed: {hash(str(pid)) % 1000:03d}")
        print()

## ðŸ—ï¸ Lab 6: Advanced HBase Features

### Exercise 6.1: Exploring HBase Features

**Objective:** Learn about advanced HBase features and use cases

**Instructions:**
1. Research HBase coprocessors
2. Learn about HBase filters
3. Understand HBase integration options
def exercise_6_1_advanced_features():
    """Exercise: Advanced HBase features"""
    print_header("Lab 6: Advanced HBase Features")

    print("ðŸš€ Advanced HBase Features to Explore:")
    print("""
1. Coprocessors
   â€¢ Server-side processing
   â€¢ Custom aggregation functions
   â€¢ Secondary indexing

2. Filters
   â€¢ Row key filters
   â€¢ Column family filters
   â€¢ Value filters

3. Integration Options
   â€¢ Hive for SQL queries
   â€¢ Spark for analytics
   â€¢ Phoenix for SQL interface

4. Performance Tuning
   â€¢ Region sizing
   â€¢ Compression options
   â€¢ Caching strategies
    """)

    print("ðŸ’¡ Real-World Use Cases:")
    print("â€¢ Facebook: Messaging storage")
    print("â€¢ Twitter: Timeline generation")
    print("â€¢ Financial: Transaction storage")
    print("â€¢ IoT: Sensor data storage")

## ANALYSIS: Lab 7: Visual Analysis

### Exercise 7.1: HBase Data Visualization

**Objective:** Visualize HBase concepts and performance characteristics

**Instructions:**
1. Create visualizations showing HBase benefits
2. Compare with traditional RDBMS approaches
3. Show scalability characteristics
def exercise_7_1_visualizations(df: pd.DataFrame):
    """Exercise: Create visualizations for HBase concepts"""
    print_header("Lab 7: Visual Analysis")

    # Create comparison visualizations
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # Plot 1: Data sparsity visualization
    null_percentages = (df.isnull().sum() / len(df) * 100).sort_values(ascending=False)
    axes[0, 0].bar(range(len(null_percentages)), null_percentages.values, color='skyblue')
    axes[0, 0].set_xticks(range(len(null_percentages)))
    axes[0, 0].set_xticklabels(null_percentages.index, rotation=45, ha='right')
    axes[0, 0].set_title('Data Sparsity in Titanic Dataset')
    axes[0, 0].set_ylabel('Percentage of NULL Values (%)')

    # Plot 2: Column family conceptual diagram
    families = ['personal', 'travel', 'outcome']
    family_sizes = [3, 3, 2]  # Approximate column counts
    axes[0, 1].bar(families, family_sizes, color=['#3498db', '#2ecc71', '#e74c3c'])
    axes[0, 1].set_title('HBase Column Families')
    axes[0, 1].set_ylabel('Number of Columns')

    # Plot 3: Performance comparison
    systems = ['RDBMS', 'HBase']
    metrics = ['Read Latency', 'Write Throughput', 'Horizontal Scaling']
    rdbms_scores = [9, 6, 3]
    hbase_scores = [7, 9, 9]

    x = np.arange(len(metrics))
    width = 0.35
    axes[1, 0].bar(x - width/2, rdbms_scores, width, label='RDBMS', alpha=0.8)
    axes[1, 0].bar(x + width/2, hbase_scores, width, label='HBase', alpha=0.8)
    axes[1, 0].set_title('Performance Comparison')
    axes[1, 0].set_xticks(x)
    axes[1, 0].set_xticklabels(metrics, rotation=45, ha='right')
    axes[1, 0].legend()
    axes[1, 0].set_ylim(0, 10)

    # Plot 4: Use case suitability
    use_cases = ['OLTP', 'Analytics', 'Big Data', 'Real-time']
    rdbms_fit = [9, 5, 2, 7]
    hbase_fit = [6, 8, 9, 8]

    axes[1, 1].plot(use_cases, rdbms_fit, 'o-', label='RDBMS', linewidth=3, markersize=8)
    axes[1, 1].plot(use_cases, hbase_fit, 's-', label='HBase', linewidth=3, markersize=8)
    axes[1, 1].set_title('Use Case Suitability')
    axes[1, 1].set_ylabel('Suitability Score (1-10)')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('student_hbase_lab_analysis.png', dpi=150, bbox_inches='tight')
    print("ANALYSIS: Visualizations saved as 'student_hbase_lab_analysis.png'")
    plt.show()

## OBJECTIVE: Lab Assessment

### Exercise 8.1: HBase Design Challenge

**Objective:** Design an HBase solution for a real-world scenario

**Scenario:** You need to store user activity logs for a large e-commerce platform.

**Requirements:**
- Store user clicks, purchases, searches
- Support real-time queries for user behavior
- Handle millions of events per day
- Enable analytics on user segments

**Deliverables:**
1. Table schema design
2. Row key design strategy
3. Column family organization
4. Query pattern analysis
def exercise_8_1_design_challenge():
    """Exercise: Real-world HBase design challenge"""
    print_header("Lab Assessment: E-commerce Activity Logs")

    print("ðŸ›’ Scenario: Design HBase for E-commerce Activity Logs")
    print("""
Requirements:
â€¢ Store user clicks, purchases, searches
â€¢ Real-time user behavior queries
â€¢ Millions of events daily
â€¢ Analytics on user segments

Data Types:
â€¢ User clicks: timestamp, url, referrer, device
â€¢ Purchases: timestamp, product_id, price, quantity
â€¢ Searches: timestamp, query, results_count, category
    """)

    print("
OBJECTIVE: Your Design Task:"    print("1. Design table schema with column families")
    print("2. Choose row key strategy")
    print("3. Plan for data distribution and access patterns")
    print("4. Consider performance and scalability")

    # Sample solution
    print("
ðŸ’¡ Sample Design:"    print("Table: user_activity")
    print("Row Key: user_id + timestamp (reversed for distribution)")
    print("Column Families:")
    print("  â€¢ clicks: url, referrer, device")
    print("  â€¢ purchases: product_id, price, quantity")
    print("  â€¢ searches: query, results_count, category")

def main():
    """Main lab function"""
    print("ðŸš€ HBase Student Hands-On Lab")
    print("=" * 50)
    print("Module 12: Scalable Computing - HBase NoSQL Database")
    print("=" * 50)

    # Check environment
    if not check_environment():
        print("ERROR: Environment check failed. Please install required packages.")
        return

    # Load data
    df = load_titanic_data()

    # Lab exercises
    schema = exercise_1_1_schema_design(df)
    exercise_2_1_basic_operations(df, schema)
    exercise_3_1_column_queries(df, schema)
    exercise_4_1_performance_comparison(df)
    exercise_5_1_row_key_design(df)
    exercise_6_1_advanced_features()
    exercise_7_1_visualizations(df)
    exercise_8_1_design_challenge()

    # Summary
    print_header("Lab Summary")

    print("OBJECTIVE: What You Learned:")
    print("1. HBase data model: row keys, column families, sparse storage")
    print("2. Basic CRUD operations with HappyBase")
    print("3. Query patterns and performance considerations")
    print("4. Schema design best practices")
    print("5. When to choose HBase vs traditional databases")

    print("
ðŸ“š Next Steps:"    print("â€¢ Try HBase with larger datasets")
    print("â€¢ Explore HBase shell commands")
    print("â€¢ Learn about HBase administration")
    print("â€¢ Study real-world HBase deployments")

    print("\nðŸ Lab completed! Great work on learning HBase!")

if __name__ == "__main__":
    main()